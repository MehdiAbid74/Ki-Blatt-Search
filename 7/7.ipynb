{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-04T18:06:21.215828500Z",
     "start_time": "2026-01-04T18:06:21.192312700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#\n",
    "#1)\n",
    "#\n",
    "#   eingabe 1 (x) + eingabe 2 (y) = (klassifizierung 1 oder 2) (a oder b)\n",
    "#\n",
    "#   2 eingabe/hidden layer, ein ausgabe layer\n",
    "#\n",
    "#   2 1\n",
    "#   2\n",
    "#\n",
    "#       F(x) = (1/(1+e1(-x)))\n",
    "#\n",
    "#       {+1 = z >= 0\n",
    "#       {-1 = z < 0\n",
    "#\n",
    "#       sign(w1*x1 + w2*x2 + b)\n",
    "#\n",
    "# x1 grenze bei 2\n",
    "# x2 grenze bei 3\n",
    "\n",
    "# sign\n",
    "# \"wenn\" x1 < 2 und x2 < 3 = (<0) -1\n",
    "# wenn x1 > 2 oder x2 > 3 = (>=0) +1\n",
    "\n",
    "# perzeptron 1 nimmt x1\n",
    "class Perceptron:\n",
    "    def __init__(self,x1,x2,idx,lay):\n",
    "        self.x1 = x1\n",
    "        self.x2 = x2\n",
    "        self.idx = idx\n",
    "        self.lay = lay\n",
    "    def print(self):\n",
    "        print(\"P:\",self.idx,\"Layer:\",self.lay,\"values x1: \",self.x1,\"x2: \",self.x2)\n",
    "P1 = Perceptron(0,1,1,1)\n",
    "P2 = Perceptron(1,0,2,1)\n",
    "\n",
    "P3 = Perceptron(0.5,0.5,3,2)\n",
    "P1.print()\n",
    "P2.print()\n",
    "P3.print()"
   ],
   "id": "f44c8830aba275f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P: 1 Layer: 1 values x1:  0 x2:  1\n",
      "P: 2 Layer: 1 values x1:  1 x2:  0\n",
      "P: 3 Layer: 2 values x1:  0.5 x2:  0.5\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# value z..b x2 = 1 + bias bzw\n",
    "# h1 = sign(0*x1 + 1*x2 -3) = x2 - 3\n",
    "# h2 = sign(1*x1 + 0*x2 - 2) =  x1 - 2\n",
    "# h11 = sign( 1*h1 + 1*h2, 1)\n",
    "\n",
    "# beipsiele x1 x2\n",
    "# 2 3  h1 = (3-3) = 0 (sign(0) = 1), h2 = (2-2) = 0 |  + 1 = 1 somit klasse 1\n",
    "# 4 3  h1 = (3-3) = 0, h2 = (4-2) = 2 |  + 1 = 3 somit klasse 1\n",
    "# 1 1  h1 = (1-3) = -2, h2 = (1-2) = -1 | + 1 = -2 somit klasse -1\n",
    "\n",
    "\n"
   ],
   "id": "428ff4e30c6f507c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# === 2) ===\n",
    "\n",
    "# Layer = 25 64 32 4\n",
    "\n",
    "# w1 = 25X64\n",
    "# w2 = 64X32\n",
    "# w3 = 32X4\n",
    "\n",
    "# b1 = 1X25\n",
    "# b2 = 1X64\n",
    "# b3 = 1X32\n",
    "\n",
    "# VorwÃ¤rtslauf:\n",
    "\n",
    "# schicht 1\n",
    "# z1 = w1 * a0 + b1         | w1 = [64x25] vektor bestimmt wie sehr jede eingabe [25] auf die 64 neuronen gewichtet wird z.b. [1,1] = 0.5\n",
    "# a1 = ReLU(z1)\n",
    "\n",
    "# schicht 2\n",
    "# z2 = w2 * a1 +b2\n",
    "# a2 = ReLU(z2)\n",
    "\n",
    "# Schicht 3\n",
    "# z3 = w3 * a2 + b3\n",
    "# y = ReLU(z3)\n",
    "\n",
    "# Vorhersage:\n",
    "# Klassifizierungsproblem\n",
    "# 1 2 3 4\n"
   ],
   "id": "ae526087abde9e4a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "(1) Logistische Regression\n",
    "\n",
    "Gaussian (linear separierbar)\n",
    "\n",
    "Entscheidungsgrenze: linear, sauber\n",
    "\n",
    "Trainings-/Testkosten: beide niedrig, Ã¤hnlich\n",
    "\n",
    "keine Ãœberanpassung\n",
    "\n",
    "Nicht-lineare DatensÃ¤tze (Circle, Spiral, XOR)\n",
    "\n",
    "Entscheidungsgrenze: zu simpel\n",
    "\n",
    "Kosten: hoch, kaum Verbesserung\n",
    "\n",
    "Viele Punkte nicht korrekt klassifizierbar â†’ Modell zu schwach\n",
    "\n",
    "(2) MLP ohne Noise (0)\n",
    "Einfluss von Neuronen & Schichten\n",
    "\n",
    "1 Schicht, 2 Neuronen\n",
    "\n",
    "Grenze: sehr grob\n",
    "\n",
    "Circle/Spiral: nicht trennbar\n",
    "\n",
    "1 Schicht, 3â€“5 Neuronen\n",
    "\n",
    "Grenze: gekrÃ¼mmt, besser\n",
    "\n",
    "Circle: meist gut, Spiral: noch schwierig\n",
    "\n",
    "2 Schichten Ã— 5 Neuronen\n",
    "\n",
    "Grenze: deutlich komplexer\n",
    "\n",
    "Spiral oft gut trennbar\n",
    "\n",
    "3â€“4 Schichten Ã— 7 Neuronen\n",
    "\n",
    "Sehr feine, verschachtelte Grenze\n",
    "\n",
    "Trainingskosten sehr niedrig\n",
    "\n",
    "Aktivierungsfunktionen\n",
    "\n",
    "Sigmoid\n",
    "\n",
    "Entscheidungsgrenze: weich / rund\n",
    "\n",
    "Training: langsam, vanishing gradients\n",
    "\n",
    "tanh\n",
    "\n",
    "Auch rund, aber stÃ¤rker & schneller als Sigmoid\n",
    "\n",
    "ReLU\n",
    "\n",
    "Grenze: stÃ¼ckweise linear (â€eckigâ€œ)\n",
    "\n",
    "schnellstes Training\n",
    "\n",
    "(3) MLP mit Noise-Level = 15\n",
    "\n",
    "Entscheidungsgrenzen werden unruhig / gezackt\n",
    "\n",
    "Tiefe & groÃŸe Netze:\n",
    "\n",
    "Trainingskosten â†“ stark\n",
    "\n",
    "Testkosten â†‘ â†’ Ãœberanpassung\n",
    "\n",
    "Ãœberanpassung, wenn:\n",
    "\n",
    "Trainingskosten weiter sinken\n",
    "\n",
    "Testkosten steigen\n",
    "\n",
    "Grenze passt sich Rauschen an\n",
    "\n",
    "Kleinere Netze generalisieren besser\n",
    "\n",
    "Allgemeine Beobachtungen\n",
    "\n",
    "Nicht alle Punkte korrekt klassifizierbar, besonders:\n",
    "\n",
    "bei Noise\n",
    "\n",
    "bei Spiral + kleinen Netzen\n",
    "\n",
    "Berechnungsgeschwindigkeit:\n",
    "\n",
    "ReLU > tanh > Sigmoid\n",
    "\n",
    "Mehr Layer = langsamer\n",
    "\n",
    "Versteckte Schichten:\n",
    "\n",
    "FrÃ¼he Schichten: einfache Muster (Linien, Kanten)\n",
    "\n",
    "SpÃ¤te Schichten: komplexe Kombinationen (â€Symboleâ€œ)\n",
    "\n",
    "Deine Vermutung stimmt âœ”ï¸\n",
    "\n",
    "Zusammenfassung (Intuition)\n",
    "\n",
    "Mehr Neuronen/Layer â†’ komplexere Entscheidungsgrenzen\n",
    "\n",
    "Zu viel davon â†’ Overfitting, besonders mit Noise\n",
    "\n",
    "Sigmoid/tanh â†’ rund & glatt\n",
    "\n",
    "ReLU â†’ eckig, schnell, effektiv\n",
    "\n",
    "Beste Modelle: ausreichend komplex, aber nicht maximal"
   ],
   "id": "b56cf521958767be"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Was macht Noise?\n",
    "\n",
    "Noise = zufÃ¤llige StÃ¶rung der Daten\n",
    "\n",
    "Datenpunkte werden vom idealen Muster weg verschoben\n",
    "\n",
    "Klassen Ã¼berlappen sich\n",
    "\n",
    "Es gibt keine perfekte Trennung mehr\n",
    "\n",
    "Effekt:\n",
    "\n",
    "Training wird schwerer\n",
    "\n",
    "Manche Punkte sind prinzipiell falsch\n",
    "\n",
    "â€Perfekt lernenâ€œ â‡’ Rauschen lernen = Overfitting\n",
    "\n",
    "Mehr Neuronen â†’ feinere Formen\n",
    "\n",
    "Jedes Neuron â‰ˆ eine einfache Trennlinie\n",
    "\n",
    "Mehr Neuronen = mehr Linien\n",
    "\n",
    "Linien werden kombiniert â†’ Kurven, Ecken, Wellen\n",
    "\n",
    "Entscheidungsgrenze wird detailreicher\n",
    "\n",
    "ğŸ§  Bildlich:\n",
    "2 Neuronen â†’ Kreis grob\n",
    "5 Neuronen â†’ Kreis glatt\n",
    "15 Neuronen â†’ Zacken & Details\n",
    "\n",
    "Mehr Layer â†’ hÃ¶here Abstraktion\n",
    "\n",
    "Erste Schicht: einfache Muster (Linien, Kanten)\n",
    "\n",
    "Mittlere Schichten: Kombinationen (BÃ¶gen, Segmente)\n",
    "\n",
    "Letzte Schicht: komplexe â€Symboleâ€œ (Spirale!)\n",
    "\n",
    "â¡ï¸ Layer bauen auf einander auf"
   ],
   "id": "97acff70b1b4577b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
